import express from 'express';
import { OpenAI } from 'openai';
import fs from 'fs';
import path from 'path';
import { logger } from '../utils/logger';

const router = express.Router();

// åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * è·å–promptæ¨¡æ¿
 */
function getPromptTemplate(inputType: string, uiLanguage: string = 'en', targetLanguage: string = 'zh-CN'): string {
  try {
    const promptPath = path.join(__dirname, '../../prompts', uiLanguage, `${targetLanguage}.json`);
    
    if (!fs.existsSync(promptPath)) {
      logger.warn(`âš ï¸ Promptæ–‡ä»¶ä¸å­˜åœ¨: ${promptPath}`);
      return getDefaultPrompt(inputType);
    }
    
    const promptData = JSON.parse(fs.readFileSync(promptPath, 'utf8'));
    const promptKey = getPromptKey(inputType);
    
    if (!promptData[promptKey]) {
      logger.warn(`âš ï¸ Prompté”®ä¸å­˜åœ¨: ${promptKey} in ${promptPath}`);
      return getDefaultPrompt(inputType);
    }
    
    return promptData[promptKey];
  } catch (error) {
    logger.error(`âŒ è¯»å–promptå¤±è´¥:`, error);
    return getDefaultPrompt(inputType);
  }
}

/**
 * æ ¹æ®è¾“å…¥ç±»å‹è·å–prompté”®
 */
function getPromptKey(inputType: string): string {
  const keyMap: { [key: string]: string } = {
    'pinyin': 'pinyin_to_chinese',
    'english': 'english_to_chinese',
    'english_sentence': 'english_sentence_to_chinese',
    'chinese': 'chinese_to_english',
    'chinese_sentence': 'chinese_sentence_to_english',
    'general': 'general_translation'
  };
  
  return keyMap[inputType] || 'general_translation';
}

/**
 * è·å–é»˜è®¤prompt
 */
function getDefaultPrompt(inputType: string): string {
  const defaultPrompts: { [key: string]: string } = {
    'pinyin': 'å°†æ‹¼éŸ³è½¬æ¢ä¸ºä¸­æ–‡è¯æ±‡ï¼Œæä¾›3-5ä¸ªå¸¸ç”¨å€™é€‰è¯',
    'english': 'å°†è‹±æ–‡å•è¯ç¿»è¯‘æˆä¸­æ–‡ï¼Œæä¾›ä¸»è¦é‡Šä¹‰',
    'english_sentence': 'å°†è‹±æ–‡å¥å­ç¿»è¯‘æˆä¸­æ–‡ï¼Œæä¾›è‡ªç„¶æµç•…çš„ç¿»è¯‘',
    'chinese': 'æä¾›ä¸­æ–‡è¯æ±‡çš„è‹±æ–‡é‡Šä¹‰å’Œä¾‹å¥',
    'chinese_sentence': 'å°†ä¸­æ–‡å¥å­ç¿»è¯‘æˆè‹±æ–‡ï¼Œæä¾›è‡ªç„¶æµç•…çš„ç¿»è¯‘',
    'general': 'æ ¹æ®è¾“å…¥ç±»å‹æä¾›é€‚å½“çš„ç¿»è¯‘æˆ–é‡Šä¹‰'
  };
  
  return defaultPrompts[inputType] || 'æä¾›ç¿»è¯‘æˆ–é‡Šä¹‰';
}

/**
 * OpenAIèŠå¤©ç«¯ç‚¹
 * POST /api/openai/chat
 */
router.post('/chat', async (req, res) => {
  try {
    const { prompt, model = 'gpt-4o-mini', max_tokens = 200, inputType = 'general', uiLanguage = 'en', targetLanguage = 'zh-CN' } = req.body;
    
    if (!prompt) {
      return res.status(400).json({
        success: false,
        error: 'Missing required parameter: prompt'
      });
    }
    
    logger.info(`ğŸ¤– OpenAIè¯·æ±‚: ${prompt} (${inputType})`);
    
    // è·å–æ™ºèƒ½promptæ¨¡æ¿
    const systemPrompt = getPromptTemplate(inputType, uiLanguage, targetLanguage);
    const fullPrompt = systemPrompt.replace('{word}', prompt);
    
    logger.info(`ğŸ“ ç³»ç»Ÿprompt: ${systemPrompt.substring(0, 100)}...`);
    logger.info(`ğŸ“ å®Œæ•´prompt: ${fullPrompt.substring(0, 200)}...`);
    
    // è°ƒç”¨OpenAI API
    const completion = await openai.chat.completions.create({
      model: model,
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.1,
      max_tokens: max_tokens
    });
    
    const responseText = completion.choices[0]?.message?.content;
    
    if (!responseText) {
      throw new Error('No response from OpenAI');
    }
    
    logger.info(`âœ… OpenAIå“åº”: ${responseText.substring(0, 100)}...`);
    
    // å°è¯•è§£æJSONå“åº”
    let parsedResponse;
    try {
      // æ¸…ç†å“åº”æ–‡æœ¬
      let cleanedResponse = responseText.trim();
      if (cleanedResponse.startsWith('```json')) {
        cleanedResponse = cleanedResponse.replace(/^```json\s*/, '');
      }
      if (cleanedResponse.startsWith('```')) {
        cleanedResponse = cleanedResponse.replace(/^```\s*/, '');
      }
      if (cleanedResponse.endsWith('```')) {
        cleanedResponse = cleanedResponse.replace(/\s*```$/, '');
      }
      
      // æ¸…ç†æ§åˆ¶å­—ç¬¦
      cleanedResponse = cleanedResponse.replace(/[\x00-\x1F\x7F-\x9F]/g, '');
      
      parsedResponse = JSON.parse(cleanedResponse);
    } catch (parseError) {
      logger.warn(`âš ï¸ JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬:`, parseError);
      parsedResponse = {
        translation: responseText,
        text: responseText
      };
    }
    
    res.json({
      success: true,
      data: parsedResponse,
      usage: completion.usage,
      model: completion.model
    });
    
  } catch (error) {
    logger.error('âŒ OpenAI APIé”™è¯¯:', error);
    res.status(500).json({
      success: false,
      error: error instanceof Error ? error.message : 'OpenAI APIè°ƒç”¨å¤±è´¥'
    });
  }
});

/**
 * OpenAIå¥åº·æ£€æŸ¥ç«¯ç‚¹
 * GET /api/openai/health
 */
router.get('/health', async (req, res) => {
  try {
    const hasOpenAIKey = !!process.env.OPENAI_API_KEY;
    
    if (!hasOpenAIKey) {
      return res.json({
        status: 'error',
        service: 'openai',
        error: 'OPENAI_API_KEY not configured'
      });
    }
    
    // ç®€å•æµ‹è¯•è¿æ¥
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: 'test' }],
      max_tokens: 5
    });
    
    res.json({
      status: 'ok',
      service: 'openai',
      model: completion.model,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    res.status(500).json({
      status: 'error',
      service: 'openai',
      error: error instanceof Error ? error.message : 'Unknown error'
    });
  }
});

export default router;
